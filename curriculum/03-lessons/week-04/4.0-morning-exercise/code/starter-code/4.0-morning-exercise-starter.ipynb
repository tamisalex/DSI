{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandertam/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n"
     ]
    }
   ],
   "source": [
    "# This dataset you have seen, but this time we will properly split the data from the actual\n",
    "# dataset into two, and fit the model on the train dataset, and test on the test dataset.\n",
    "# Then we will iterate through class thresholds, to see which threshold gives the best confusion\n",
    "# matrix. The first steps have been done for you \n",
    "# (creating dummies, joining to df, creating y series and features only dataframe \n",
    "# but please be familiar with these first steps! \n",
    "\n",
    "df_raw = pd.read_csv(\"../../assets/admissions.csv\")\n",
    "df = df_raw.dropna() \n",
    "\n",
    "dummies = pd.get_dummies( df[\"prestige\"], prefix = \"prestige\" )\n",
    "\n",
    "print df.head()\n",
    "\n",
    "join = df[ df.columns[0:3] ].join(dummies)\n",
    "join[\"intercept\"] = 1\n",
    "\n",
    "joinColumns = join.columns\n",
    "y = join.admit\n",
    "X = join[ joinColumns[1:3] + joinColumns[4:] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data randomly into datasets, 70% train, 30% test using test train split\n",
    "# HINT: X_train, X_test, y_train, y_test = train_test_split( parameters )\n",
    "# call them X_train, X_test, y_train, and y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.567931\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   277</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   271</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 21 Jul 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.09148</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>09:33:17</td>     <th>  Log-Likelihood:    </th> <td> -157.32</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -173.16</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>6.873e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>          <td>    0.9387</td> <td>    0.401</td> <td>    2.342</td> <td> 0.019</td> <td>    0.153     1.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>          <td>    0.0024</td> <td>    0.001</td> <td>    1.805</td> <td> 0.071</td> <td>   -0.000     0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>    <td>   -4.6529</td> <td>    1.349</td> <td>   -3.450</td> <td> 0.001</td> <td>   -7.296    -2.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_2.0</th> <td>   -0.5204</td> <td>    0.379</td> <td>   -1.374</td> <td> 0.169</td> <td>   -1.263     0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_3.0</th> <td>   -1.2389</td> <td>    0.414</td> <td>   -2.996</td> <td> 0.003</td> <td>   -2.050    -0.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>prestige_4.0</th> <td>   -1.4674</td> <td>    0.527</td> <td>   -2.782</td> <td> 0.005</td> <td>   -2.501    -0.434</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  277\n",
       "Model:                          Logit   Df Residuals:                      271\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Thu, 21 Jul 2016   Pseudo R-squ.:                 0.09148\n",
       "Time:                        09:33:17   Log-Likelihood:                -157.32\n",
       "converged:                       True   LL-Null:                       -173.16\n",
       "                                        LLR p-value:                 6.873e-06\n",
       "================================================================================\n",
       "                   coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------\n",
       "gpa              0.9387      0.401      2.342      0.019         0.153     1.724\n",
       "gre              0.0024      0.001      1.805      0.071        -0.000     0.005\n",
       "intercept       -4.6529      1.349     -3.450      0.001        -7.296    -2.010\n",
       "prestige_2.0    -0.5204      0.379     -1.374      0.169        -1.263     0.222\n",
       "prestige_3.0    -1.2389      0.414     -2.996      0.003        -2.050    -0.428\n",
       "prestige_4.0    -1.4674      0.527     -2.782      0.005        -2.501    -0.434\n",
       "================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model using statsmodels.api.sm\n",
    "# HINT: sm.logit(y_train, X_train) then fit it\n",
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11a9bbf90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib\n",
    "\n",
    "sns.lmplot(\"gpa\",\"admit\",join, logistic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandertam/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "      <th>intercept</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>predictedAdmit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.05</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>3.95</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>3.39</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3.45</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.239390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>4.00</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>3.20</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2.86</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>3.19</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3.02</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2.86</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.61</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.13</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>3.30</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3.94</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.281753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4.00</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.19</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.169124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3.07</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3.15</td>\n",
       "      <td>460.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.112960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2.81</td>\n",
       "      <td>760.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>3.78</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>3.77</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>3.24</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3.18</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>3.12</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3.88</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3.12</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>3.49</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.74</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.203718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.57</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>3.00</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3.40</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>3.51</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.56</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>3.81</td>\n",
       "      <td>520.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2.93</td>\n",
       "      <td>460.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>3.32</td>\n",
       "      <td>660.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>3.17</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2.84</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>3.63</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3.52</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4.00</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>3.21</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3.54</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>3.72</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3.52</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.242640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>3.95</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.39</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3.85</td>\n",
       "      <td>680.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>3.78</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>3.63</td>\n",
       "      <td>620.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>3.47</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.15</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>3.17</td>\n",
       "      <td>640.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>3.58</td>\n",
       "      <td>460.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3.74</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3.32</td>\n",
       "      <td>560.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.159550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2.78</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3.19</td>\n",
       "      <td>540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.292240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2.93</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>3.88</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gpa    gre  intercept  prestige_2.0  prestige_3.0  prestige_4.0  \\\n",
       "35   3.05  400.0          1           1.0           0.0           0.0   \n",
       "342  3.95  500.0          1           0.0           0.0           1.0   \n",
       "284  3.39  440.0          1           1.0           0.0           0.0   \n",
       "74   3.45  720.0          1           0.0           0.0           1.0   \n",
       "360  4.00  520.0          1           0.0           0.0           0.0   \n",
       "338  3.20  540.0          1           0.0           0.0           0.0   \n",
       "238  2.86  500.0          1           0.0           0.0           1.0   \n",
       "262  3.19  520.0          1           0.0           1.0           0.0   \n",
       "222  3.02  480.0          1           0.0           0.0           0.0   \n",
       "155  2.86  580.0          1           0.0           0.0           1.0   \n",
       "0    3.61  380.0          1           0.0           1.0           0.0   \n",
       "38   3.13  500.0          1           1.0           0.0           0.0   \n",
       "164  3.30  580.0          1           1.0           0.0           0.0   \n",
       "142  3.94  620.0          1           0.0           0.0           1.0   \n",
       "70   4.00  640.0          1           0.0           1.0           0.0   \n",
       "3    3.19  640.0          1           0.0           0.0           1.0   \n",
       "196  3.07  660.0          1           0.0           1.0           0.0   \n",
       "129  3.15  460.0          1           0.0           0.0           1.0   \n",
       "355  2.81  760.0          1           0.0           0.0           0.0   \n",
       "354  3.78  540.0          1           1.0           0.0           0.0   \n",
       "167  3.77  720.0          1           0.0           1.0           0.0   \n",
       "166  3.24  440.0          1           0.0           0.0           1.0   \n",
       "60   3.18  620.0          1           1.0           0.0           0.0   \n",
       "274  3.12  520.0          1           1.0           0.0           0.0   \n",
       "124  3.88  720.0          1           0.0           1.0           0.0   \n",
       "78   3.12  540.0          1           0.0           0.0           0.0   \n",
       "381  3.49  540.0          1           1.0           0.0           0.0   \n",
       "27   3.74  520.0          1           0.0           0.0           1.0   \n",
       "97   3.57  480.0          1           1.0           0.0           0.0   \n",
       "112  3.00  360.0          1           0.0           1.0           0.0   \n",
       "..    ...    ...        ...           ...           ...           ...   \n",
       "146  3.40  480.0          1           1.0           0.0           0.0   \n",
       "170  3.51  400.0          1           0.0           1.0           0.0   \n",
       "17   2.56  360.0          1           0.0           1.0           0.0   \n",
       "241  3.81  520.0          1           0.0           0.0           0.0   \n",
       "366  2.93  460.0          1           0.0           1.0           0.0   \n",
       "273  3.32  660.0          1           0.0           0.0           0.0   \n",
       "247  3.17  440.0          1           1.0           0.0           0.0   \n",
       "315  2.84  300.0          1           1.0           0.0           0.0   \n",
       "376  3.63  620.0          1           1.0           0.0           0.0   \n",
       "96   3.52  640.0          1           0.0           0.0           1.0   \n",
       "395  4.00  620.0          1           1.0           0.0           0.0   \n",
       "251  3.21  620.0          1           0.0           0.0           1.0   \n",
       "126  3.54  600.0          1           0.0           0.0           0.0   \n",
       "117  3.72  700.0          1           1.0           0.0           0.0   \n",
       "141  3.52  700.0          1           0.0           0.0           1.0   \n",
       "257  3.95  620.0          1           0.0           1.0           0.0   \n",
       "8    3.39  540.0          1           0.0           1.0           0.0   \n",
       "63   3.85  680.0          1           0.0           1.0           0.0   \n",
       "374  3.78  560.0          1           1.0           0.0           0.0   \n",
       "367  3.63  620.0          1           0.0           1.0           0.0   \n",
       "223  3.47  800.0          1           0.0           1.0           0.0   \n",
       "42   3.15  600.0          1           1.0           0.0           0.0   \n",
       "388  3.17  640.0          1           1.0           0.0           0.0   \n",
       "321  3.58  460.0          1           1.0           0.0           0.0   \n",
       "150  3.74  800.0          1           0.0           0.0           0.0   \n",
       "61   3.32  560.0          1           0.0           0.0           1.0   \n",
       "365  2.78  480.0          1           0.0           1.0           0.0   \n",
       "128  3.19  540.0          1           1.0           0.0           0.0   \n",
       "93   2.93  580.0          1           1.0           0.0           0.0   \n",
       "181  3.88  500.0          1           0.0           0.0           1.0   \n",
       "\n",
       "     predictedAdmit  \n",
       "35         0.205621  \n",
       "342        0.228988  \n",
       "284        0.281608  \n",
       "74         0.239390  \n",
       "360        0.586183  \n",
       "338        0.412221  \n",
       "238        0.096460  \n",
       "262        0.160967  \n",
       "222        0.339040  \n",
       "155        0.114515  \n",
       "0          0.169048  \n",
       "38         0.261781  \n",
       "164        0.335058  \n",
       "142        0.281753  \n",
       "70         0.353639  \n",
       "3          0.169124  \n",
       "196        0.193394  \n",
       "129        0.112960  \n",
       "355        0.451768  \n",
       "354        0.418067  \n",
       "167        0.348142  \n",
       "166        0.116674  \n",
       "60         0.331334  \n",
       "274        0.269300  \n",
       "124        0.371926  \n",
       "78         0.394154  \n",
       "381        0.353674  \n",
       "27         0.203718  \n",
       "97         0.338126  \n",
       "112        0.098596  \n",
       "..              ...  \n",
       "146        0.303385  \n",
       "170        0.162694  \n",
       "17         0.067488  \n",
       "241        0.542363  \n",
       "366        0.115176  \n",
       "273        0.511371  \n",
       "247        0.241769  \n",
       "315        0.143275  \n",
       "376        0.430514  \n",
       "96         0.217196  \n",
       "395        0.516882  \n",
       "251        0.165065  \n",
       "126        0.527018  \n",
       "117        0.499122  \n",
       "141        0.242640  \n",
       "257        0.332265  \n",
       "8          0.195388  \n",
       "63         0.343440  \n",
       "374        0.429774  \n",
       "367        0.269269  \n",
       "223        0.328041  \n",
       "42         0.314696  \n",
       "388        0.339931  \n",
       "321        0.329552  \n",
       "150        0.684670  \n",
       "61         0.159550  \n",
       "365        0.106045  \n",
       "128        0.292240  \n",
       "93         0.262560  \n",
       "181        0.217594  \n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add y_test as a new column in X_test, and then make another dataframe called dfTrain\n",
    "# and set it equal to X_test, after X_test has the new y_test column\n",
    "# HINT: X_test[\"actualAdmit\"] = y_test\n",
    "\n",
    "# create a new column in dfTrain that is the predicted admitance value using the result logit model\n",
    "# note you will need a dataframe with only the features (including intercept)\n",
    "# note the dummy column has already been removed\n",
    "\n",
    "# HINT: \n",
    "#dfTrain['predictedAdmit'] = result.predict( dfTrain[ listOfFeatureCols ] )\n",
    "\n",
    "X_test[\"actualAdmit\"] = y_test\n",
    "dfTrain = X_test.iloc[:,:-1]\n",
    "dfTrain['predictedAdmit'] = result.predict( dfTrain )\n",
    "dfTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a function call scalePredictor, that will take two parameters called \"prob\" and \"threshold\"\n",
    "# the function will check if the probability is greater than or equal to the threshold, \n",
    "# return 1 if true, else return 0\n",
    "\n",
    "# create a while loop, starting at i = 0.30 and ending i <= 0.50, in increments of 0.01. \n",
    "# In this while loop you will create a new predictionAdmit_Threshold column in every iteration\n",
    "# this column will be populated by using scalePredictor each time\n",
    "# after the new column is populated, print out a confusion matrix (use crosstab (within the loop!) )\n",
    "# note the first parameter in crosstab will always be dfTrain['actualAdmit'] while the second\n",
    "# parameter will be the new column in that iteration\n",
    "# interpret each iteration, and decide on the best threshold in each iteration.\n",
    "\n",
    "# HINTS:\n",
    "\n",
    "#i = 0.30\n",
    "#while i <= 0.50:\n",
    "    \n",
    "#    dfTrain[ 'predictedAdmit_{}'.format(i) ] = finish code here\n",
    "    \n",
    "#    print pd.crosstab(\n",
    "#        dfTrain['actualAdmit'],\n",
    "#        put new dfTrain column here, \n",
    "#        rownames=['admit']\n",
    "#    )\n",
    "#    i += 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
